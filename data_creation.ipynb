{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07fccf9e",
   "metadata": {},
   "source": [
    "## Database Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f11e46d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "458db9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re \n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import codecs\n",
    "import unidecode\n",
    "import contractions\n",
    "from bs4 import BeautifulSoup \n",
    "import praw\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa9fe21",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2349ac17",
   "metadata": {},
   "source": [
    "to create a dataset containing the WSB comments, we complete an existing dataset with more recent data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fe7bdb",
   "metadata": {},
   "source": [
    "#### Kaggle  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad2fd9b",
   "metadata": {},
   "source": [
    "the dataset can be downloaded [here](https://www.kaggle.com/theriley106/wallstreetbetscomments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60419354",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = []\n",
    "for line in open('data/wsbData.json', 'r'):\n",
    "    empty.append(json.loads(line))\n",
    "df_kaggle = pd.DataFrame(empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67410428",
   "metadata": {},
   "source": [
    "format the dataframe : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df36fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert unix timestamp\n",
    "df_kaggle['date_created'] = pd.to_datetime(df_kaggle['created_utc'].astype(int), unit='s')\n",
    "df_kaggle['date'] = df_kaggle['date_created'].dt.date\n",
    "df_kaggle = df_kaggle.drop_duplicates(subset='body', keep=\"last\")\n",
    "df_kaggle = df_kaggle[[\"date\", \"body\"]]\n",
    "df_kaggle.columns = [\"date\", \"text\"]\n",
    "df_kaggle = df_kaggle.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b392329",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle.to_pickle(\"data/df_kaggle.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a92861e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2496853"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0755c444",
   "metadata": {},
   "source": [
    "#### Reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "449eeeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get data from pushshift api\n",
    "def getPushshiftData(query, after, before, sub):\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission/?title='+str(query)+'&size=1000&after='+str(after)+'&before='+str(before)+'&subreddit='+str(sub)\n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    return data['data']\n",
    "\n",
    "# get relevant data from data extracted using previous function\n",
    "def collectSubData(subm):\n",
    "    subData = [subm['id'], subm['title'], subm['url'], datetime.datetime.fromtimestamp(subm['created_utc']).date()]\n",
    "    try:\n",
    "        flair = subm['link_flair_text']\n",
    "    except KeyError:\n",
    "        flair = \"NaN\"\n",
    "    subData.append(flair)\n",
    "    subStats.append(subData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f2e3d4",
   "metadata": {},
   "source": [
    "request the data as of the last date of the kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5849336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "sub = 'wallstreetbets'\n",
    "before = \"1640217600\" #dec 23 2021\n",
    "after =  \"1541030400\" #nov 1 2018 \n",
    "1541030400\n",
    "query = \"Daily Discussion Thread\"\n",
    "subCount = 0\n",
    "subStats = []\n",
    "\n",
    "data = getPushshiftData(query, after, before, sub)\n",
    "while len(data) > 0:\n",
    "    for submission in data:\n",
    "        collectSubData(submission)\n",
    "        subCount+=1\n",
    "    after = data[-1]['created_utc']\n",
    "    data = getPushshiftData(query, after, before, sub) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5b228b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize data into dataframe\n",
    "data={}\n",
    "ids=[]\n",
    "titles=[]\n",
    "urls=[]\n",
    "dates=[]\n",
    "flairs=[]\n",
    "for stat in subStats:\n",
    "    ids.append(stat[0])\n",
    "    titles.append(stat[1])\n",
    "    urls.append(stat[2])\n",
    "    dates.append(stat[3])\n",
    "    flairs.append(stat[4])\n",
    "data['id']=ids\n",
    "data['title']=titles\n",
    "data['url']=urls\n",
    "data['date']=dates\n",
    "data['flair']=flairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0576d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5f0ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = dict(zip(df_api.id, df_api.url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da683c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 798/798 [1:08:09<00:00,  5.12s/it]\n"
     ]
    }
   ],
   "source": [
    "# connect to reddit api\n",
    "reddit = praw.Reddit(client_id='OkOXFwArjdjJt3BBU9d_9A', client_secret='MnNW34sKNwhiLiOPN27YENdjVV5hdg', user_agent='wsb crawler',check_for_async=False)\n",
    "comments_by_day = {}\n",
    "# collect comments using praw\n",
    "for id_, url in tqdm(urls.items()):\n",
    "    try:\n",
    "        submission = reddit.submission(url=url)\n",
    "        submission.comments.replace_more(limit=0)\n",
    "        comments= [(comment.body) for comment in submission.comments]\n",
    "    except:\n",
    "        comments=None\n",
    "    comments_by_day[id_] = comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3af63d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api['comment'] = df_api['id'].map(comments_by_day)\n",
    "df_api[\"comment\"] = df_api[\"comment\"].apply(lambda com: \". \".join(com) if com!=None else np.nan)\n",
    "df_api = df_api[df_api['comment'].notna()]\n",
    "df_api = df_api.drop_duplicates(subset='comment', keep=\"last\")\n",
    "df_api = df_api[[\"date\", \"comment\"]]\n",
    "df_api.columns = [\"date\", \"text\"]\n",
    "df_api = df_api.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cddd5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api.to_pickle(\"data/df_api.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc93e9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "749"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889b46fa",
   "metadata": {},
   "source": [
    "#### SPY prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3e9b521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df_spy = yf.download('SPY', start='2011-01-01')\n",
    "df_spy = df_spy.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a25a4b",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56f7ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle = pd.read_pickle(\"data/df_kaggle.pkl\")\n",
    "df_api = pd.read_pickle(\"data/df_api.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a49863f",
   "metadata": {},
   "source": [
    "merge the dataframes and process the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc3d5e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = df_kaggle.append(df_api)\n",
    "df_base = df_base.dropna()\n",
    "df_base = df_base.groupby(\"date\")[\"text\"].agg(lambda x: '. '.join(x)).to_frame()\n",
    "df_base = df_base.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25daf5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2012, 4, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f73c919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2021, 12, 22)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.date.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c346d476",
   "metadata": {},
   "source": [
    "add the spy prices and create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9ef88a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spy[\"label\"] = df_spy[\"Close\"].pct_change().shift(-1)\n",
    "df_spy = df_spy.set_index(\"Date\")\n",
    "df_spy = df_spy.resample(\"D\").asfreq().bfill()\n",
    "# merge the SPY\n",
    "df_base[\"date\"] = pd.to_datetime(df_base[\"date\"], format='%Y-%m-%d')\n",
    "df_base = df_base.merge(df_spy, left_on='date', right_on='Date')\n",
    "df_base = df_base.set_index('date')\n",
    "df_base = df_base[df_base['label'].notna()]\n",
    "df_base[\"label\"] = np.where(df_base[\"label\"]>0, 1, 0)\n",
    "df_base = df_base[[\"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "145e125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.to_csv(\"data/database_aug.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a949f875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3019"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65e5ed6",
   "metadata": {},
   "source": [
    "### Data process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2519644a",
   "metadata": {},
   "source": [
    "#### improve comments readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580eee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newlines_tabs(text): \n",
    "    # remove newline and tabs\n",
    "    text = text.replace('\\\\n', ' ').replace('\\n', ' ').replace('\\t',' ').replace('\\\\', ' ').replace('. com', '.com')\n",
    "    return text\n",
    "\n",
    "def remove_deleted_username(text):\n",
    "    # remove username \"deleted\"\n",
    "    return text.replace('[deleted]', \"\")\n",
    "\n",
    "def strip_html_tags(text):\n",
    "    # remove html tags\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text(separator=\" \")\n",
    "    return stripped_text\n",
    "\n",
    "def remove_links(text):\n",
    "    # remove links\n",
    "    remove_https = re.sub(r'http\\S+', '', text)\n",
    "    remove_com = re.sub(r\"\\ [A-Za-z]*\\.com\", \" \", remove_https)\n",
    "    return remove_com\n",
    "\n",
    "def remove_whitespace(text):\n",
    "    # remove white spaces\n",
    "    pattern = re.compile(r'\\s+') \n",
    "    wo_whitespace = re.sub(pattern, ' ', text)\n",
    "    text = wo_whitespace.replace('?', ' ? ').replace(')', ' ) ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e72eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base[\"text\"] = df_base[\"text\"].apply(remove_newlines_tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0142e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base[\"text\"] = df_base[\"text\"].apply(remove_deleted_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639bc176",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base[\"text\"] = df_base[\"text\"].apply(strip_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca54bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base[\"text\"] = df_base[\"text\"].apply(remove_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462dd797",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base[\"text\"] = df_base[\"text\"].apply(remove_whitespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2437ddd7",
   "metadata": {},
   "source": [
    "#### cleaning the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b1aecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accented_characters_removal(text):\n",
    "    # remove accents\n",
    "    try:\n",
    "        decoded = unidecode.unidecode(codecs.decode(text, 'unicode_escape'))\n",
    "    except:\n",
    "        decoded = unidecode.unidecode(text)\n",
    "    # format weird apostrophe\n",
    "    apostrophe_handled = re.sub(\"’\", \"'\", text)\n",
    "    return apostrophe_handled\n",
    "\n",
    "def lower_casing_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "def reducing_incorrect_character_repeatation(text):\n",
    "    # Pattern matching for all case alphabets\n",
    "    pattern_alpha = re.compile(r\"([A-Za-z])\\1{1,}\", re.DOTALL)\n",
    "    # Limiting all the  repeatation to two characters.\n",
    "    formatted_text = pattern_alpha.sub(r\"\\1\\1\", text) \n",
    "    # Pattern matching for all the punctuations that can occur\n",
    "    pattern_punct = re.compile(r'([.,/#!$%^&*?;:{}=_`~()+-])\\1{1,}')\n",
    "    # Limiting punctuations in previously formatted string to only one.\n",
    "    combined_formatted = pattern_punct.sub(r'\\1', formatted_text)\n",
    "    # The below statement is replacing repeatation of spaces that occur more than two times with that of one occurrence.\n",
    "    final_formatted = re.sub(' {2,}',' ', combined_formatted)\n",
    "    return final_formatted\n",
    "\n",
    "def expand_contractions(text):\n",
    "    # contractions expansion\n",
    "    text = [contractions.fix(word) for word in text.split(' ')]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "def removing_special_characters(text):\n",
    "    # remove special characters\n",
    "    text = re.sub(r\"[^a-zA-Z0-9:$-,%.?!]+\", ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b669d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base[\"text\"] = df_base[\"text\"].apply(accented_characters_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b23997",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base[\"text\"] = df_base[\"text\"].apply(lower_casing_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a07c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base[\"text\"] = df_base[\"text\"].apply(reducing_incorrect_character_repeatation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42b6b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base[\"text\"] = df_base[\"text\"].apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1216d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base[\"text\"] = df_base[\"text\"].apply(removing_special_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0d5807",
   "metadata": {},
   "source": [
    "### Convert to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddd268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.to_csv(\"data/database_aug_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b2c90b",
   "metadata": {},
   "source": [
    "### Wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d408636",
   "metadata": {},
   "source": [
    "Create a term document matrix on aggregated monthly discussion threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbcb132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api = df_api.reset_index()\n",
    "df_api.date = pd.to_datetime(df_api.date, format='%Y-%m-%d')\n",
    "# corpus of aggreagated monthly discussion threads\n",
    "df_wc = df_api.groupby([df_api.date.dt.year,df_api.date.dt.month])[\"text\"].agg(lambda x: '. '.join(x))\n",
    "df_wc = df_wc.to_frame()\n",
    "corpus = df_wc.text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93590777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# term document matrix\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range = (1,1), max_df = .6, min_df = .01)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = X.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a3c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.transpose()\n",
    "data.columns = df_wc.index.to_list()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754aab22",
   "metadata": {},
   "source": [
    "Create the wordcloud with specific formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3439c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_color_func(word, font_size, position,orientation,random_state=None, **kwargs):\n",
    "    return(\"hsl(0,100%, 1%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d16bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    font_path = '/Library/Fonts/Arial Unicode.ttf', \n",
    "    background_color=\"white\", \n",
    "    width=3000, \n",
    "    height=2000, \n",
    "    max_words=500\n",
    ")\n",
    "\n",
    "wordcloud.generate_from_frequencies(data[(2021, 1)]) # on January 2021\n",
    "wordcloud.recolor(color_func = black_color_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9320f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,10])\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('jan21_wc.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
